{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegNet-v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_type = 'null' #null/fixed/dynamic_greedy/dynamic_kmeans\n",
    "dataset_class_toremove = 'all' #all/[class_name] e.g. dolphin\n",
    "dataset_portion = 0.05\n",
    "\n",
    "experiment_name = 'v4_' + exp_type + '_' + dataset_class_toremove + str(dataset_portion)\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from commons import *\n",
    "from net import Net\n",
    "from trainer import Trainer\n",
    "import evaluate\n",
    "from data_loader import DataClass\n",
    "from data_collector import DataCollector\n",
    "from utils import *\n",
    "\n",
    "%matplotlib notebook\n",
    "#If you need to change the above line, change matlibplotlib.use() in plotter.py accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pin_mem_perm = False #TODO: should be True\n",
    "num_training_epochs = 150\n",
    "\n",
    "learning_rate, batch_size = 0.01, 128\n",
    "update_parents_enc, dynamic_hierarchy_flag = True, True\n",
    "hierarchy_update_method = None\n",
    "parent_enc_update_interval, hierarchy_update_interval = 50, 1000\n",
    "kmeans_num_clusters = 25\n",
    "do_print, do_plot = True, False\n",
    "\n",
    "myassertList(exp_type, ['null', 'fixed', 'dynamic_greedy', 'dynamic_kmeans'])\n",
    "if exp_type == 'null':\n",
    "    update_parents_enc, dynamic_hierarchy_flag = False, False\n",
    "elif exp_type == 'fixed':\n",
    "    update_parents_enc, dynamic_hierarchy_flag = True, False\n",
    "elif exp_type == 'dynamic_greedy':\n",
    "    update_parents_enc, dynamic_hierarchy_flag = True, True\n",
    "    hierarchy_update_method = 'greedy'\n",
    "elif exp_type == 'dynamic_kmeans':\n",
    "    update_parents_enc, dynamic_hierarchy_flag = True, True\n",
    "    hierarchy_update_method = 'kmeans'\n",
    "    kmeans_num_clusters = 25\n",
    "\n",
    "data_class = DataClass('data/')\n",
    "data_collector = DataCollector('tmp/', experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model = model.cuda() if use_cuda else model\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(data_collector,\n",
    "                  learning_rate = learning_rate,\n",
    "                  use_hierarchy = update_parents_enc,\n",
    "                  dynamic_hierarchy_flag = dynamic_hierarchy_flag,\n",
    "                  parent_enc_update_interval = parent_enc_update_interval,\n",
    "                  hierarchy_update_interval = hierarchy_update_interval,\n",
    "                  hierarchy_update_method = hierarchy_update_method,\n",
    "                  kmeans_num_clusters = kmeans_num_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To actually perform hyper-parameter tuning, uncomment the following lines.\n",
    "\n",
    "#data_class.load(batch_size, validation_portion=0.3,\n",
    "#                portion_to_keep = data_class.updatePortionToKeep(dataset_class_toremove, dataset_portion),\n",
    "#                pin_mem_perm=pin_mem_perm)\n",
    "#(lambda_1_best, lambda_2_best) = trainer.hyperParamTuning(model, data_class,\n",
    "#                                                          [2**i for i in range(-15,-5)],\n",
    "#                                                          [2**i for i in range(-15,-5)])\n",
    "lambda_1_best = 2**(-12)\n",
    "lambda_2_best = 2**(-8)\n",
    "print('Hyper-parameter tuning finished! \\t lambda_1 = %f, lambda_2 = %f' %(lambda_1_best, lambda_2_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network\n",
    "Using the best hyper-parameter found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_class.load(batch_size, validation_portion=0.0,\n",
    "                portion_to_keep = data_class.updatePortionToKeep(dataset_class_toremove, dataset_portion),\n",
    "                pin_mem_perm=pin_mem_perm)\n",
    "trainer.train(model, data_class,\n",
    "              lambda_1=lambda_1_best, lambda_2=lambda_2_best,\n",
    "              num_epochs=num_training_epochs,\n",
    "              do_print=False, do_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the final model and related data on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_collector.finalizeModel(state='final', dst_root='results/')\n",
    "data_collector.finilizeHierarchy(hierarchy=trainer.getNamedHierarchy(data_class), dst_root='results/')\n",
    "#data_collector.finalizeLosses(state='running', dst_root='results/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training error acheived during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from plotter import Plotter\n",
    "\n",
    "plotter = Plotter(2,1)\n",
    "[plot_losses, plot_seen_samples] = data_collector.loadLosses('running')\n",
    "plot_avg_losses = []\n",
    "for i in range(len(plot_losses)):\n",
    "    plot_avg_losses.append(sum(plot_losses[:i+1])/(i+1))\n",
    "\n",
    "plotter.update(plot_seen_samples, [plot_losses, plot_avg_losses], 0)\n",
    "plotter.update(plot_seen_samples[-50:], [plot_losses[-50:]], 1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the final learnt hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get the hierarchy from trainer\n",
    "named_hierarchy = trainer.getNamedHierarchy(data_class)\n",
    "#Or load it from the stored file\n",
    "#named_hierarchy = np.load('results/'+experiment_name+'/models/final_hierarchy.npy').take(0)\n",
    "for parent, children in named_hierarchy.items():\n",
    "    print('Superclass {0}'.format(parent+1), ':')\n",
    "    print(children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the network on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate.top1(model, data_class.testloader)\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * accuracy))\n",
    "\n",
    "accuracy_topk = evaluate.topK(model, data_class.testloader, 5)\n",
    "print('Accuracy of the network on the 10000 test images (top-5): %d %%' % (\n",
    "    100 * accuracy_topk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the network on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate.top1(model, data_class.trainloader)\n",
    "print('Accuracy of the network on training images: %d %%' % (\n",
    "    100 * accuracy))\n",
    "\n",
    "accuracy_topk = evaluate.topK(model, data_class.trainloader, 5)\n",
    "print('Accuracy of the network on training images (top-5): %d %%' % (\n",
    "    100 * accuracy_topk))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
